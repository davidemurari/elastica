{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzvFW1OnHklV"
      },
      "source": [
        "# Main part of the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9q-Sn9mIciK"
      },
      "source": [
        "#### Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J10IbrFs3OT"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "!pip install optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.autograd.functional import jacobian as jac\n",
        "from torch.func import jacfwd, vmap\n",
        "from csv import writer\n",
        "import optuna #for hyperparameter search\n",
        "\n",
        "from scripts.createDataset import getData, getDataLoaders\n",
        "from scripts.utils import getBCs\n",
        "from scripts.network import approximate_curve\n",
        "from scripts.training import trainModel\n",
        "from scripts.evaluateModel import plotTestResults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZSovV7Wczb4"
      },
      "outputs": [],
      "source": [
        "#We do this so Pytorch works in double precision\n",
        "torch.set_default_dtype(torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJQy9f1dMtjT",
        "outputId": "06ffac78-cd08-45a1-901d-d5ef358f2951"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7l2rASEIgtu"
      },
      "source": [
        "#### Importing and organising data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create the dataset as follows:\n",
        "\n",
        "Input : (q_1,q_2,v_1,v_2,s)\n",
        "Output : (q(s),v(s))\n",
        "\n",
        "With the trajectories that we have available, we can hence generate a dataset of size\n",
        "N_elements+1 x N_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7AdGuZ2Mc8T"
      },
      "outputs": [],
      "source": [
        "#Importing and shuffling the trajectories\n",
        "\n",
        "trajectories = np.loadtxt(\"data/generated_data.txt\")\n",
        "number_samples,number_components = trajectories.shape\n",
        "#Randomize the order of the trajectories\n",
        "indices = np.random.permutation(len(trajectories))\n",
        "trajectories = trajectories[indices]\n",
        "\n",
        "number_elements = int(number_components/4)-1\n",
        "data_train, data_test = getData(number_elements,number_samples,trajectories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZEskggrI0zk"
      },
      "source": [
        "#### Training the neural network iterating over the training batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmhHT3cMULbB"
      },
      "outputs": [],
      "source": [
        "def define_model(trial):\n",
        "    normalize = trial.suggest_categorical(\"normalize\",[True,False])\n",
        "    act = trial.suggest_categorical(\"act\",['tanh','sigmoid','sin','relu2'])\n",
        "    nlayers = trial.suggest_int(\"n_layers\", 1, 4)\n",
        "    hidden_nodes = trial.suggest_int(\"hidden_nodes\", 10, 100)\n",
        "    correct_functional = trial.suggest_categorical(\"correct_functional\",[True,False])\n",
        "\n",
        "    model = approximate_curve(normalize,act, nlayers, hidden_nodes, correct_functional)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QNrylGbURvx"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "  \n",
        "    torch.manual_seed(1)\n",
        "    np.random.seed(1)\n",
        "  \n",
        "    # Generate the model.\n",
        "    model = define_model(trial)\n",
        "    model.to(device);\n",
        "\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4 , 1e-1, log=True)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\",0,5e-4)\n",
        "    #optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "    #optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    #optimizer = torch.optim.LBFGS(model.parameters(),lr=lr, max_iter=100,tolerance_grad=1.e-10,\n",
        "    #                                  tolerance_change=1.e-10, history_size=100, line_search_fn='strong_wolfe')\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "    batch_size = 32 # trial.suggest_int(\"batch_size\", 32, 64)\n",
        "\n",
        "    trainloader, testloader = getDataLoaders(batch_size,data_train,data_test)\n",
        "\n",
        "    print(\"Current test with :\\n\\n\")\n",
        "    for key, value in trial.params.items():\n",
        "      print(\"    {}: {}\".format(key, value))\n",
        "    print(\"\\n\\n\")\n",
        "\n",
        "    epochs = 100\n",
        "    loss = trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader)\n",
        "    test_error = 100\n",
        "    if not torch.isnan(loss):\n",
        "      model.eval();\n",
        "\n",
        "      def eval_model(s,q1,q2,v1,v2):\n",
        "        s_ = torch.tensor([[s]],dtype=torch.float32).to(device)\n",
        "        q1 = torch.from_numpy(q1.astype(np.float32)).reshape(1,-1).to(device)\n",
        "        q2 = torch.from_numpy(q2.astype(np.float32)).reshape(1,-1).to(device)\n",
        "        v1 = torch.from_numpy(v1.astype(np.float32)).reshape(1,-1).to(device)\n",
        "        v2 = torch.from_numpy(v2.astype(np.float32)).reshape(1,-1).to(device)\n",
        "        return model(s_,q1,q2,v1,v2).detach().cpu().numpy()[0]\n",
        "\n",
        "      bcs = getBCs(trajectories)\n",
        "      q1 = bcs[\"q1\"]\n",
        "      q2 = bcs[\"q2\"]\n",
        "      v1 = bcs[\"v1\"]\n",
        "      v2 = bcs[\"v2\"]\n",
        "\n",
        "      xx = np.linspace(0, 1, number_elements+1)\n",
        "      res = np.zeros((50,2,len(xx)))\n",
        "\n",
        "      for j in range(50):\n",
        "          for i in range(len(xx)):\n",
        "              res[j,:,i] = eval_model(xx[i],q1[j],q2[j],v1[j],v2[j])\n",
        "\n",
        "      q_x_pred_torch = torch.from_numpy(res[:,0].astype(np.float32))\n",
        "      q_x_true_torch = torch.from_numpy(trajectories[:50,np.arange(0,number_components,4)].astype(np.float32))\n",
        "\n",
        "      q_y_pred_torch = torch.from_numpy(res[:,1].astype(np.float32))\n",
        "      q_y_true_torch = torch.from_numpy(trajectories[:50,np.arange(1,number_components,4)].astype(np.float32))\n",
        "\n",
        "      test_error = criterion(q_x_pred_torch,q_x_true_torch).item() + criterion(q_y_pred_torch,q_y_true_torch).item()\n",
        "\n",
        "    #Saving the obtained results\n",
        "    if trial.number == 0:\n",
        "        labels = []\n",
        "        for lab, _ in trial.params.items():\n",
        "            labels.append(str(lab))\n",
        "        labels.append(\"Test error\")\n",
        "        with open(\"savedResults/results.csv\", \"a\") as f_object:\n",
        "            writer_object = writer(f_object)\n",
        "            writer_object.writerow(labels)\n",
        "            f_object.close()\n",
        "\n",
        "    results = []\n",
        "    for _, value in trial.params.items():\n",
        "        results.append(str(value))\n",
        "\n",
        "    results.append(test_error)\n",
        "\n",
        "    with open(\"savedResults/results.csv\", \"a\") as f_object:\n",
        "        writer_object = writer(f_object)\n",
        "        writer_object.writerow(results)\n",
        "        f_object.close()\n",
        "\n",
        "    return test_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZdWqmBOWfng",
        "outputId": "cd196361-8bc6-4ced-fd48-ce1d21b337f0"
      },
      "outputs": [],
      "source": [
        "optuna_study = input(\"Do you want to do hyperparameter test? Type Yes or No \")\n",
        "params = {}\n",
        "if optuna_study==\"Yes\":\n",
        "    optuna_study = True\n",
        "else:\n",
        "    optuna_study = False\n",
        "if optuna_study:\n",
        "    study = optuna.create_study(direction=\"minimize\",study_name=\"Euler Elastica\")\n",
        "    study.optimize(objective, n_trials=100)\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    \n",
        "    params = study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot the results for the best combination of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if params=={}:\n",
        "    print(\"No parameters have been specified. Let's input them:\\n\\n\")\n",
        "    normalize = input(\"Normalize is True or False? \")==\"True\"\n",
        "    act = input(\"What activation function to use? Choose among 'sin', 'sigmoid', 'sin', 'relu2': \")\n",
        "    nlayers = int(input(\"How many layers do you want the network to have? \"))\n",
        "    hidden_nodes = int(input(\"How many hidden nodes do you want the network to have? \"))\n",
        "    correct_functional = input(\"Type True if you want to impose by design the BCs, False otherwise: \")\n",
        "    lr = float(input(\"What learning rate do you want to use? \"))\n",
        "    weight_decay = float(input(\"What weight decay do you want to use? \"))\n",
        "    \n",
        "    params = {\"normalize\": normalize,\n",
        "              \"act\": act,\n",
        "              \"n_layers\":nlayers,\n",
        "              \"hidden_nodes\":hidden_nodes,\n",
        "              \"correct_functional\":correct_functional,\n",
        "              \"lr\":lr,\n",
        "              \"weight_decay\":weight_decay}    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_best_model():\n",
        "    normalize = params[\"normalize\"]\n",
        "    act = params[\"act\"]\n",
        "    nlayers = params[\"n_layers\"]\n",
        "    hidden_nodes = params[\"hidden_nodes\"]\n",
        "    correct_functional = params[\"correct_functional\"]\n",
        "\n",
        "    model = approximate_curve(normalize,act, nlayers, hidden_nodes, correct_functional)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = define_best_model()\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = params[\"weight_decay\"]\n",
        "lr = params[\"lr\"]\n",
        "#optimizer = torch.optim.LBFGS(model.parameters(),lr=lr, max_iter=100,tolerance_grad=1.e-10,\n",
        "#                                  tolerance_change=1.e-10, history_size=100, line_search_fn='strong_wolfe')\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "trainloader, testloader = getDataLoaders(batch_size,data_train,data_test)\n",
        "epochs = 100\n",
        "loss = trainModel(number_elements,device,model,criterion,optimizer,epochs,trainloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval();\n",
        "plotTestResults(model,device,number_elements,number_components,trajectories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "ed7ab7e2e8a9240e70ddeb3e0a5d2646d3f0c1850e1b729c718218fffe2c99a3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
